import streamlit as st
import pandas as pd
import numpy as np
import faiss
from openai import OpenAI
from dotenv import load_dotenv
import os

# APIã‚­ãƒ¼èª­ã¿è¾¼ã¿
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY", "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"))

# ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã ã‘èª­ã¿è¾¼ã¿
@st.cache_resource
def load_rag_data():
    index = faiss.read_index("rag_faiss.index")
    df = pd.read_pickle("rag_records.pkl")
    return index, df

index, df = load_rag_data()

# UIæ§‹æˆ
st.title("ğŸ§© éšœå®³è¨ºæ–­ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆï¼ˆRAGç‰ˆï¼‰")

query_process = st.text_input("éšœå®³å·¥ç¨‹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "")
query_failure = st.text_input("éšœå®³å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "")

if st.button("è¨ºæ–­ã™ã‚‹") and query_process and query_failure:
    query = f"éšœå®³å·¥ç¨‹: {query_process}, éšœå®³å†…å®¹: {query_failure}"
    
    # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=[query]
    )
    query_vec = np.array(response.data[0].embedding).astype("float32").reshape(1, -1)

    # FAISSæ¤œç´¢ï¼ˆä¸Šä½3ä»¶ï¼‰
    D, I = index.search(query_vec, k=3)
    similar_records = df.iloc[I[0]]
    examples_text = "\n\n".join(similar_records["text"].tolist())

    # GPTç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    prompt = f"""
ã‚ãªãŸã¯è£½é€ ç¾å ´ã®éšœå®³è¨ºæ–­ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®éšœå®³å±¥æ­´ã‚’å‚è€ƒã«ã—ã¦ã€éšœå®³å·¥ç¨‹ã€Œ{query_process}ã€ãŠã‚ˆã³éšœå®³å†…å®¹ã€Œ{query_failure}ã€ã«å¯¾ã—ã¦ã€
æœ€ã‚‚å¯èƒ½æ€§ã®é«˜ã„ã€Œå•é¡Œå·¥ç¨‹ã€ã€Œéšœå®³åŸå› ã€ã€Œå¯¾å‡¦å†…å®¹ã€ã‚’æœ€å¤§3ä»¶æ¨å®šã—ã¦ãã ã•ã„ã€‚
ãã®ä¸Šã§ã€ãªãœãã‚Œã‚’æ¨å®šã—ãŸã®ã‹ã‚’è‡ªç„¶æ–‡ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

ã€é‡è¦ã€‘
- å›ç­”ã¯ä»¥ä¸‹ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã«è¨˜è¼‰ã•ã‚ŒãŸå†…å®¹ã®ã¿ã«é™å®šã—ã¦ãã ã•ã„ã€‚
- è¨˜è¼‰ã®ãªã„å·¥ç¨‹ã‚„åŸå› ãƒ»å¯¾å‡¦ã‚’ä½¿ã£ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚
- ã©ã®å±¥æ­´ã‚’æ ¹æ‹ ã¨ã—ãŸã‹ï¼ˆå±¥æ­´1ã€œ3ãªã©ï¼‰ã‚‚æ˜è¨˜ã—ã¦ãã ã•ã„ã€‚

å±¥æ­´ï¼š
{examples_text}

ã€å‡ºåŠ›å½¢å¼ã€‘
æ¨å®šï¼š
- å•é¡Œå·¥ç¨‹: â—‹â—‹
- éšœå®³åŸå› : â—‹â—‹
- å¯¾å‡¦å†…å®¹: â—‹â—‹

ç†ç”±ï¼š
ã€œã€œ
"""

    gpt_response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}]
    )

    st.subheader("ğŸ§  GPTã®è¨ºæ–­çµæœ")
    st.markdown(gpt_response.choices[0].message.content)

